{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f401df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python36.zip\n",
      "/usr/lib/python3.6\n",
      "/usr/lib/python3.6/lib-dynload\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages\n",
      "/usr/lib/python3/dist-packages\n",
      "/usr/local/lib/python3.6/dist-packages/IPython/extensions\n",
      "/root/.ipython\n",
      "../../Analysis/Util/\n",
      "../../Database/\n",
      "../../Database/Tables\n",
      "../\n",
      "../\n",
      "../../Analysis/Util\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "rootDir = \"../../\"\n",
    "sys.path.append(rootDir + \"Analysis/Util/\")\n",
    "sys.path.append(rootDir + \"Database/\")\n",
    "\n",
    "from DatabaseAPI import DatabaseAPI\n",
    "import numpy as np\n",
    "from get_time_interval_data import *\n",
    "\n",
    "from Mapping import *\n",
    "from PCA import *\n",
    "import pickle\n",
    "\n",
    "for stuff in sys.path:\n",
    "    print(stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03cf0b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "'''\n",
    "simpleMapper() maps the following:\n",
    "DOA (Direction of Arrival) -> Real Room Space (x,y,z,etc.)\n",
    "according to the following parameters:\n",
    "- numDOA : Number of DOAs (depending on number of arrays)\n",
    "- outDim : Number of Dimensions (2 for 2D space, 3 for 3D space, etc.)\n",
    "'''\n",
    "\n",
    "class classificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "\n",
    "class simpleMapper():\n",
    "    def __init__(self, numDOA=15, outDim=2):\n",
    "        super().__init__()\n",
    "        H = 64\n",
    "        self.network = torch.nn.Sequential(\n",
    "                torch.nn.Linear(numDOA, H),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(H, outDim),\n",
    "            )\n",
    "#         self.network = nn.Sequential(\n",
    "            \n",
    "#             nn.Conv1d(numDOA, 32, kernel_size = 3, padding = 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv1d(32,64, kernel_size = 3, stride = 1, padding = 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool1d(2,2),\n",
    "        \n",
    "#             nn.Conv1d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv1d(128 ,128, kernel_size = 3, stride = 1, padding = 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool1d(2,2),\n",
    "            \n",
    "#             nn.Conv1d(128, 256, kernel_size = 3, stride = 1, padding = 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv1d(256,256, kernel_size = 3, stride = 1, padding = 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool1d(2,2),\n",
    "            \n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(82944,1024),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(1024, 512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(512,outDim)\n",
    "#         )\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fd1a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigRoom = pickle.load(open(\"../../Analysis/Util/bigEnufSecondTable.p\", \"rb\"))\n",
    "\n",
    "# Available Mics: [0,1,3,4,5]\n",
    "CP_LIST = bigRoom[\"cp_list\"]\n",
    "ROOM_LIST = bigRoom[\"room_list\"]\n",
    "\n",
    "# Available Mics: [0,1,2,3,4,5]\n",
    "square_DOA = bigRoom[\"square_DOA\"]\n",
    "square_Matrix = bigRoom[\"square_Matrix\"]\n",
    "\n",
    "square_raw = bigRoom[\"sqRaw\"]\n",
    "cp_raw = bigRoom[\"cpRaw\"]\n",
    "\n",
    "# Available Mics: [0,1,2,3,4,5]\n",
    "rectangle_DOA = bigRoom[\"rectangle_DOA\"]\n",
    "rectangle_Matrix = bigRoom[\"rectangle_Matrix\"]\n",
    "\n",
    "# Available Mics: [0,1,2,3,4,5]\n",
    "table1_DOA = bigRoom[\"table1_DOA\"]\n",
    "table1_Matrix = bigRoom[\"table1_Matrix\"]\n",
    "\n",
    "# Available Mics: [0,1,2,3,4,5]\n",
    "table2_DOA = bigRoom[\"table2_DOA\"]\n",
    "table2_Matrix = bigRoom[\"table2_Matrix\"]\n",
    "\n",
    "# Available Mics: [0,1,2,3,4,5]\n",
    "table3_DOA = bigRoom[\"table3_DOA\"]\n",
    "table3_Matrix = bigRoom[\"table3_Matrix\"]\n",
    "\n",
    "# Available Mics: [0,1,2,3,4,5]\n",
    "table4_DOA = bigRoom[\"table4_DOA\"]\n",
    "table4_Matrix = bigRoom[\"table4_Matrix\"]\n",
    "\n",
    "CP_INDICES = [i for i in range(24)]\n",
    "\n",
    "np.vstack([ROOM_LIST[i] for i in CP_INDICES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b079f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CP _ 1 =  (400, 15)\n"
     ]
    }
   ],
   "source": [
    "print(\"CP _ 1 = \", CP_LIST[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "406a7b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOM_LIST:  (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"ROOM_LIST: \", ROOM_LIST[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e04c3d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Number of samples in CPoints:  400\n",
      "1 Number of samples in CPoints:  400\n",
      "2 Number of samples in CPoints:  400\n",
      "3 Number of samples in CPoints:  400\n",
      "4 Number of samples in CPoints:  400\n",
      "5 Number of samples in CPoints:  400\n",
      "6 Number of samples in CPoints:  400\n",
      "7 Number of samples in CPoints:  400\n",
      "8 Number of samples in CPoints:  400\n",
      "9 Number of samples in CPoints:  400\n",
      "10 Number of samples in CPoints:  400\n",
      "11 Number of samples in CPoints:  400\n",
      "12 Number of samples in CPoints:  400\n",
      "13 Number of samples in CPoints:  400\n",
      "14 Number of samples in CPoints:  400\n",
      "15 Number of samples in CPoints:  400\n",
      "16 Number of samples in CPoints:  400\n",
      "17 Number of samples in CPoints:  400\n",
      "18 Number of samples in CPoints:  400\n",
      "19 Number of samples in CPoints:  400\n",
      "20 Number of samples in CPoints:  400\n",
      "21 Number of samples in CPoints:  400\n",
      "22 Number of samples in CPoints:  400\n",
      "23 Number of samples in CPoints:  400\n",
      "cp_stacked shape:  (9600, 15)\n",
      "room_stacked shape:  (9600, 2)\n",
      "room list length =  24\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idx, cPoints in enumerate(CP_LIST) :\n",
    "    numSamples = cPoints.shape[0]\n",
    "    print(idx, \"Number of samples in CPoints: \", numSamples)\n",
    "    room_sampled = np.vstack([ROOM_LIST[idx] for i in range(numSamples)])\n",
    "    \n",
    "    if int(idx) == 0:\n",
    "        cp_stacked = cPoints\n",
    "        room_stacked = room_sampled\n",
    "    else :\n",
    "        cp_stacked = np.vstack([cp_stacked, cPoints])\n",
    "        room_stacked = np.vstack([room_stacked, room_sampled])\n",
    "    \n",
    "    \n",
    "print(\"cp_stacked shape: \", cp_stacked.shape)\n",
    "print(\"room_stacked shape: \", room_stacked.shape)\n",
    "print(\"room list length = \", len(ROOM_LIST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6453cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "\n",
    "class calibrationPoints(torch.utils.data.Dataset) :\n",
    "    def __init__(self, cp_list, room_list, transforms) :\n",
    "        for idx, cPoints in enumerate(cp_list) :\n",
    "            numSamples = cPoints.shape[0]\n",
    "#             print(idx, \"Number of samples in CPoints: \", numSamples)\n",
    "            room_sampled = np.vstack([ROOM_LIST[idx] for i in range(numSamples)])\n",
    "\n",
    "            if int(idx) == 0:\n",
    "                self.cp_stacked = cPoints\n",
    "                self.room_stacked = room_sampled\n",
    "            else :\n",
    "                self.cp_stacked = np.vstack([self.cp_stacked, cPoints])\n",
    "                self.room_stacked = np.vstack([self.room_stacked, room_sampled])\n",
    "                \n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        cp = self.cp_stacked[idx, :]\n",
    "        roomPoint = self.room_stacked[idx, :]\n",
    "        \n",
    "        return cp, roomPoint\n",
    "        \n",
    "    def __len__(self) :\n",
    "        return len(self.cp_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cf0b887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch.utils' from '/usr/local/lib/python3.6/dist-packages/torch/utils/__init__.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "861ea080",
   "metadata": {},
   "outputs": [],
   "source": [
    "cPoints = calibrationPoints(CP_LIST, ROOM_LIST, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0a8066f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cPoints (array([-0.1225  , -0.653625,  0.746875,  0.13575 ,  0.103125,  0.985   ,\n",
      "        0.685   ,  0.136   ,  0.7155  ,  0.702875, -0.145875,  0.69625 ,\n",
      "       -0.463   , -0.411625,  0.784875]), array([70., 70.]))\n"
     ]
    }
   ],
   "source": [
    "print(\"cPoints\", cPoints[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93bc1272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "\n",
    "__all__ = ['get_mean_and_std', 'init_params', 'mkdir_p', 'AverageMeter']\n",
    "\n",
    "\n",
    "def get_mean_and_std(dataset):\n",
    "    '''Compute the mean and std value of dataset.'''\n",
    "    dataloader = trainloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "\n",
    "    mean = torch.zeros(15, dtype=torch.float64)\n",
    "    std = torch.zeros(15, dtype=torch.float64)\n",
    "    print('==> Computing mean and std..')\n",
    "    for inputs, targets in dataloader:\n",
    "        for i in range(15):\n",
    "#             print(\"inputs shape: \", inputs.shape)\n",
    "            mean[i] += inputs[:,i].mean()\n",
    "            std[i] += inputs[:,i].std()\n",
    "    mean.div_(len(dataset))\n",
    "    std.div_(len(dataset))\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3ee7cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Computing mean and std..\n",
      "Mean :  tensor([-0.4882, -0.1784,  0.6722,  0.4819, -0.1172,  0.8130,  0.2071,  0.4055,\n",
      "         0.8004,  0.2610, -0.0434,  0.8733, -0.0186, -0.5051,  0.7604],\n",
      "       dtype=torch.float64)\n",
      "STD  :  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "mean, std = get_mean_and_std(cPoints)\n",
    "print(\"Mean : \", mean)\n",
    "print(\"STD  : \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c9d500c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "net = simpleMapper()\n",
    "batch_size=128\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "val_size = 1000\n",
    "train_size = len(cPoints) - val_size\n",
    "train_ds, val_ds = random_split(cPoints, [train_size, val_size])\n",
    "len(train_ds), len(val_ds)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02a2808d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs, lbls = next(iter(train_loader))\n",
    "imgs[7].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f5678f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 61643795.96875\n",
      "199 61644143.84375\n",
      "299 61645044.328125\n",
      "399 61644972.015625\n",
      "499 61643758.5\n",
      "599 61645255.625\n",
      "699 61646209.4375\n",
      "799 61646852.390625\n",
      "899 61642479.484375\n",
      "999 61643627.015625\n",
      "1099 61640102.578125\n",
      "1199 61642705.75\n",
      "1299 61645965.96875\n",
      "1399 61645839.015625\n",
      "1499 61645895.140625\n",
      "1599 61645010.078125\n",
      "1699 61645244.609375\n",
      "1799 61638671.515625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-532d659aef80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# in Tensors with requires_grad=True, so this call will compute gradients for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# all learnable parameters in the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# Update the weights using gradient descent. Each parameter is a Tensor, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 15, 100, 2\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "# is a Module which contains other Modules, and applies them in sequence to\n",
    "# produce its output. Each Linear Module computes output from input using a\n",
    "# linear function, and holds internal Tensors for its weight and bias.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ")\n",
    "\n",
    "# The nn package also contains definitions of popular loss functions; in this\n",
    "# case we will use Mean Squared Error (MSE) as our loss function.\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "\n",
    "learning_rate = 1e-4\n",
    "for t in range(5000):\n",
    "    total_loss = 0\n",
    "    for DOAs, coord in train_loader :\n",
    "    \n",
    "        DOAs, coord = DOAs.type(torch.FloatTensor), coord.type(torch.FloatTensor)\n",
    "        # Forward pass: compute predicted y by passing x to the model. Module objects\n",
    "        # override the __call__ operator so you can call them like functions. When\n",
    "        # doing so you pass a Tensor of input data to the Module and it produces\n",
    "        # a Tensor of output data.\n",
    "        y_pred = model(DOAs)\n",
    "\n",
    "        # Compute and print loss. We pass Tensors containing the predicted and true\n",
    "        # values of y, and the loss function returns a Tensor containing the\n",
    "        # loss.\n",
    "        loss = loss_fn(y_pred, coord)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Zero the gradients before running the backward pass.\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to all the learnable\n",
    "        # parameters of the model. Internally, the parameters of each Module are stored\n",
    "        # in Tensors with requires_grad=True, so this call will compute gradients for\n",
    "        # all learnable parameters in the model.\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
    "        # we can access its gradients like we did before.\n",
    "        with torch.no_grad():\n",
    "            for param in model.parameters():\n",
    "                param -= learning_rate * param.grad\n",
    "                \n",
    "    if t % 100 == 99:\n",
    "        print(t, total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f31884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
