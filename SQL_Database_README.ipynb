{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook documents the code used for uploading data onto the SQL database.\n",
    "\n",
    "\n",
    "This code is present in ./SQL_AllProc. The Raspberry Pi's upload their log files onto Yihan's google drive. We have scripts running in ./SQL_AllProc which process these logs and upload them to a SQL database on the CSE server. There scripts are run periodically using cron on the server.\n",
    "\n",
    "If you open cron on Ardel's account, you should see a total of 6 lines corresponding to this database related preprocessing steps.\n",
    "\n",
    "When it comes to uploading file data to the database, there are 3 important scripts:\n",
    "\n",
    "1. **log_folder_poll_general_del.py**: polls the mounted drive folder corresponding to the array number, and shifts the files into processing. After doing so, calls the script logfile_uploader_del.py on the log file to upload it into the SQL database.\n",
    "2. **logfile_uploader_del.py**: extracts log data into a dataframe. Creates database engine using SQLAlchemy, and appends the data to the raw table in the database. Takes one argument, which is the path of the log file to process (Usually, the file is in the 'Processing' directory when this is called.). Moves the file to processed. This script is called from the log_folder_poll_general_del.py script.\n",
    "3. **sync_to_multiDimMatrix_red_fluc.py**: Called every 5 minutes from cron. Takes data from 10 minutes ago from the raw table and quantizes the time according to interval specified in script. A group by aspect of the query ensures that data from all arrays is combined. Thus, new rows of multiDimMatrix, another table in our database, are created. Uses SQLAlchemy to push these rows to multiDimMatrix.\n",
    "\n",
    "\n",
    "### All these scripts are available in ./SQL_python_scripts_non_working_copies. These copies have been documented in good detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step: locate create table queries and document them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On May 9th, Yihan and Chaitanya noticed that extractDirectionalities function in log_file_uploader was a previous version, and they restored it to the new version such that data from all sources is being taken. Prior to this, there was an issue with inserting values into the raw table in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
